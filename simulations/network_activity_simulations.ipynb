{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Network activity simulations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Modules to import\n",
    "# Note: due to some changes in Tgt cells and the way synaptic conductance variables are changed \n",
    "#           as well as how networks might vary, I chose not to write a class to run simulations on network activity \n",
    "#       additionally, the 'Setting up network' took a minute to finish, hence initializing a new \n",
    "#           instance of a class would take a while, hence I found it easier to do this \n",
    "# Network configuration file was created using MATLAB for Model N*\n",
    "from __future__ import division\n",
    "import numpy as np \n",
    "import matplotlib as mpl\n",
    "from brian2 import *\n",
    "from brian2.core.variables import *\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "import networkx as nx \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "from scipy import io as scio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Equations and globals \n",
    "\n",
    "prefs.codegen.target = 'cython'\n",
    "\n",
    "glob = {'dt': 0.05*ms, 'tstop': 200*ms}\n",
    "const = {'E_AMPA' : 0*mV, 'E_GABA' : -80*mV, \n",
    "         'tau_AMPA' : 2*ms, 'tau_GABA' : 10*ms}\n",
    "\n",
    "\n",
    "eqs_neuron = '''\n",
    "    dv/dt = (1/C)*(k*(v-v_r)*(v-v_t)/mV - u + I_app + I_syn) : volt\n",
    "    du/dt = int(1-is_fs)*a*(b*(v-v_r) - u) + int(is_fs)*a*(big_U-u): amp\n",
    "    big_U = int(v>=v_b)*b*((v-v_b)**3)/(mV*mV) : amp\n",
    " \n",
    "    I_app = i0*(t>=ti)*(t<=tf) + i_hold : amp\n",
    "    I_syn = I_elec + I_AMPA + I_GABA : amp \n",
    "\n",
    "    I_elec : amp\n",
    "    I_AMPA : amp \n",
    "    I_GABA : amp \n",
    "    C : farad\n",
    "    v_r : volt\n",
    "    v_t : volt\n",
    "    v_p : volt\n",
    "    k : amp/volt\n",
    "    a : 1/second\n",
    "    b : amp/volt\n",
    "    c : volt\n",
    "    d : amp\n",
    "    is_fs : 1\n",
    "    v_b : volt\n",
    "    e_vpu : volt/amp\n",
    "    e_cu : volt/amp\n",
    "    e_du : amp\n",
    "    i0 : amp \n",
    "    i_hold : amp\n",
    "    ti : second\n",
    "    tf : second\n",
    "\n",
    "'''\n",
    "eqs_AMPA = '''\n",
    "    g_AMPA : siemens \n",
    "    I_AMPA_post = g_AMPA*(E_AMPA-v)*s_AMPA : amp (summed)\n",
    "    ds_AMPA/dt = -s_AMPA/tau_AMPA : 1 (clock-driven) \n",
    "'''\n",
    "eqs_pre_glut = '''\n",
    "    s_AMPA += 1\n",
    "'''\n",
    "eqs_GABA = '''\n",
    "    g_GABA : siemens \n",
    "    I_GABA_post = g_GABA*(E_GABA-v)*s_GABA : amp (summed)\n",
    "    ds_GABA/dt = -s_GABA/tau_GABA : 1  (clock-driven) \n",
    "'''\n",
    "eqs_pre_gaba = '''\n",
    "    s_GABA += 1\n",
    "'''\n",
    "eqs_elec = '''\n",
    "    g_elec:siemens\n",
    "    I_elec_post = g_elec*(v_pre-v_post) : amp (summed)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Loading PARAMS + NETCON \n",
    "# Both Model Na and Model Nb have ID 'Net_3'\n",
    "# Since this has N_unit = 50 \n",
    "# Hence N = num_neurons = 50*3 = 150\n",
    "# Creation of network configuration and adjacency matrix was done in MATLAB\n",
    "# Refer to 'create_net_adj_mat.m' file\n",
    "PRM_FILE = '../prm_files/prm.yaml'\n",
    "NET_FILE = '../prm_files/extended_net_con.yaml'\n",
    "NET_NAME = 'Net_3'\n",
    "\n",
    "netgraph = yaml.load(open(NET_FILE))[NET_NAME]\n",
    "param = yaml.load(open(PRM_FILE))\n",
    "N = shape(netgraph['nodes'])[0]\n",
    "cell_names = np.asarray(netgraph['nodes'])[:,0]\n",
    "cell_types = np.asarray(netgraph['nodes'])[:,1]\n",
    "connections = np.asarray(netgraph['edges'])\n",
    "\n",
    "cell_dict = []\n",
    "for it in cell_types: \n",
    "    cell_dict.append(param[it])\n",
    "unit_dict = param['units']\n",
    "init_vals = {} \n",
    "for k in cell_dict[0].iterkeys():\n",
    "    init_vals[k] = [_cd[k] for _cd in cell_dict]  * eval(unit_dict[k])\n",
    "init_states = init_vals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Necessary functions \n",
    "def indexOfCell(cell_names, cell_name2find):\n",
    "    return np.where(np.array(cell_names) == cell_name2find)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total setup time = 60.396 s\n"
     ]
    }
   ],
   "source": [
    "# Setting up network \n",
    "setup_startT = time.time()\n",
    "G = NeuronGroup(N=N, model=eqs_neuron, threshold='v >= v_p + e_vpu*u',\\\n",
    "                reset='v = c + e_cu*u; u = (u+d)*(u+d<e_du) + e_du*(u+d>=e_du)', method='euler')\n",
    "S_elec = Synapses(G, G, model=eqs_elec)\n",
    "S_AMPA = Synapses(G, G, model=eqs_AMPA, on_pre=eqs_pre_glut, method='euler') \n",
    "S_GABA = Synapses(G, G, model=eqs_GABA, on_pre=eqs_pre_gaba, method='euler') \n",
    "for key in const.keys(): \n",
    "    val = float(const[key])\n",
    "    dim = const[key].dim\n",
    "    G.variables.add_constant(key, val, dim)\n",
    "    S_elec.variables.add_constant(key, val, dim)\n",
    "    S_AMPA.variables.add_constant(key, val, dim)\n",
    "    S_GABA.variables.add_constant(key, val, dim)\n",
    "\n",
    "non_zeros_conn = np.where(connections != '0')\n",
    "for i,j in zip(*non_zeros_conn):\n",
    "    conn_ij_raw = connections[i,j] \n",
    "    for conn_ij in conn_ij_raw.split('-'): \n",
    "        if conn_ij.upper() == 'ELEC': # SYMMETRICAL ELECTRICAL SYNAPSE \n",
    "            S_elec.connect(i=i,j=j)\n",
    "            S_elec.connect(i=j,j=i)\n",
    "        elif conn_ij.upper() == 'AMPA':\n",
    "            S_AMPA.connect(i=i,j=j)\n",
    "        elif conn_ij.upper() == 'GABA':\n",
    "            S_GABA.connect(i=i,j=j)\n",
    "        else:\n",
    "            print \"pair (%d, %d) - value = %s \" %(i,j,conn_ij)\n",
    "            raise ValueError('Cannot accept any other values representing '\\\n",
    "                             'synapses except \"0\", \"ELEC\", \"AMPA\" or \"GABA\"')\n",
    "monitor = SpikeMonitor(G,record=True)\n",
    "net = Network()\n",
    "net.add(G, S_elec, S_AMPA, S_GABA, monitor)    \n",
    "\n",
    "# this will save the initialized stage \n",
    "net.store('initialized')\n",
    "setup_endT = time.time()\n",
    "print('Total setup time = %.3f s' %(setup_endT-setup_startT))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Testing one example \n",
    "Model Na and Model Nb are basically run with similar frameworks \n",
    "\n",
    "50 number of units - each unit comprises of 1 Src, 1 Int, 1 Tgt like Model 1a\n",
    "\n",
    "$\\sigma_{inp}$ : t_init_std\n",
    "\n",
    "$G_{elec} = \\frac{\\Sigma G_{elec}}{N_{Int}} $ : (Int,ELEC,Int), g_elec_int_to_int*\n",
    "\n",
    "$G_{GABA \\rightarrow Int} = \\frac{\\Sigma G_{GABA \\rightarrow Int}}{N_{Int}} $ : (Int,GABA,Int), g_GABA_Int2Int_total\n",
    "\n",
    "Model Na : $\\Sigma G_{GABA \\rightarrow Int} = 0$\n",
    "\n",
    "Model Nb : $\\Sigma G_{GABA \\rightarrow Int} \\ne 0$\n",
    "\n",
    "Refer to \"Loading PARAMS + NETCON\" in \"Initialization\" for more information on network configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a single simulation took 3.42 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 150)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing one simulation \n",
    "\n",
    "glob = {'dt': 0.05*ms, 'tstop': 200*ms}\n",
    "startT = time.time() \n",
    "\n",
    "# this will not exactly look for labels 'Int', 'Tgt' nor 'Src' \n",
    "#       like in subthreshold simulations,\n",
    "#       but instead will be used as template because \n",
    "# ** the labels are 'Int_1', 'Int_2', ...\n",
    "# G_elec and G_GABA between Ints are normalized \n",
    "# Other types of synaptic conductances are not \n",
    "#       because, for example, only Src_1 -> Tgt_1,\n",
    "#       while Src_1 does not -> Tgt_2\n",
    "# note: the variable 'N' here does not represent number of units\n",
    "#       it represents number of neurons \n",
    "#       hence number of units = N/3 = N_Int = N_Src = N_Tgt \n",
    "# the code was written before the names of the models were agreed upon\n",
    "#       hence the tiny confusion \n",
    "syn = {('Int','ELEC','Int') : 5*nS/(N/3), \n",
    "       ('Src','AMPA','Tgt') : 20*nS,\n",
    "       ('Src','AMPA','Int') : 5*nS,\n",
    "       ('Int','GABA','Tgt') : 10*nS, \n",
    "       ('Int','GABA','Int') : 0*nS/(N/3)\n",
    "        } \n",
    "\n",
    "\n",
    "# call the initialzed state again \n",
    "net.restore('initialized')\n",
    "\n",
    "# now start changing the synaptic conductances accordingly  \n",
    "# this might take some time \n",
    "# also, this is the stage where the actual network in mind matters\n",
    "# hence, why I did not create a general class for this \n",
    "for c_s in syn.keys():\n",
    "    if size(c_s) != 3 : \n",
    "        raise ValueError('Each \"customed-synapse dict\" key needs be a 3-element tuple '\\\n",
    "                         '(\"source_name\", \"synapse_type\", \"target_name\")')\n",
    "    for i in xrange(int(N/3)): \n",
    "        for j in xrange(int(N/3)): \n",
    "            if (c_s[0] == c_s[2] and i != j) or (c_s[0] != c_s[2] and i == j):\n",
    "                src_loc = indexOfCell(cell_names,c_s[0] + '_%02d' %(i+1)) \n",
    "                tgt_loc = indexOfCell(cell_names,c_s[2] + '_%02d' %(j+1)) \n",
    "                val2replace = syn[c_s] \n",
    "                if c_s[1].upper() == 'ELEC': # SYMMETRICAL ELECTRICAL SYNAPSE \n",
    "                    S_elec.g_elec[S_elec.indices[src_loc,tgt_loc]] = val2replace \n",
    "                    S_elec.g_elec[S_elec.indices[tgt_loc,src_loc]] = val2replace\n",
    "                elif c_s[1].upper() == 'AMPA':\n",
    "                    S_AMPA.g_AMPA[S_AMPA.indices[src_loc,tgt_loc]] = val2replace\n",
    "                elif c_s[1].upper() == 'GABA':\n",
    "                    S_GABA.g_GABA[S_GABA.indices[src_loc,tgt_loc]] = val2replace\n",
    "                else: \n",
    "                    raise ValueError('Cannot accept any other values like \"%s\" representing '\\\n",
    "                                     'synapses except \"0\", \"ELEC\", \"AMPA\" or \"GABA\"' %(c_s[1]))  \n",
    "\n",
    "# 't_init_mean'around 50 to not collect data with t <0 \n",
    "inp = {'t_init_mean': 50, 't_init_std' : 5, 't_duration': 20}\n",
    "\n",
    "# initialize input to Src variables \n",
    "init_states['i0'] = np.zeros(N) * pA\n",
    "init_states['ti'] = np.zeros(N) * ms\n",
    "init_states['tf'] = np.zeros(N) * ms\n",
    "init_states['i_hold'] = np.zeros(N) * pA\n",
    "\n",
    "# generate a normal distribution of t_init_inp \n",
    "#        within 0 and (tstop - 100) = 100\n",
    "#        centered around mean = 50\n",
    "\n",
    "ti_inp = np.sort(np.random.normal(inp['t_init_mean'],inp['t_init_std'],int(N/3)+1))\n",
    "while size(np.where(np.logical_and(ti_inp < 0, ti_inp > glob['tstop']/ms - 100))[0]) > 0:\n",
    "    ti_inp = np.sort(np.random.normal(inp['t_init_mean'],inp['t_init_std'],int(N/3)+1))\n",
    "td_inp = inp['t_duration']\n",
    "saved_td_inp = [] \n",
    "\n",
    "for i in xrange(N): \n",
    "    c_n = cell_names[i]\n",
    "    if 'Int' in c_n : \n",
    "        init_states['i_hold'][i] = 50*pA\n",
    "    if 'Src' in c_n :\n",
    "        if size(ti_inp) != 0:\n",
    "            ti_i = ti_inp[-1]; ti_inp = ti_inp[:-1]\n",
    "            saved_td_inp.append(ti_i)\n",
    "            init_states['i0'][i] = 300*pA\n",
    "            init_states['ti'][i] = ti_i*ms\n",
    "            init_states['tf'][i] = (ti_i+td_inp)*ms\n",
    "    if 'Tgt' in c_n : \n",
    "        # Tgt's Izhikevich model paramters were changed\n",
    "        # to make it more excitable \n",
    "        init_states['i_hold'][i] = 10*pA\n",
    "        init_states['v_t'][i] = -45*mV\n",
    "        init_vals['C'][i] = 50*pF\n",
    "G.set_states(init_states)\n",
    "defaultclock.dt = glob['dt']\n",
    "net.run(glob['tstop'])\n",
    "\n",
    "endT = time.time() \n",
    "print(\"Running a single simulation took %.2f s\" %(endT-startT))\n",
    "\n",
    "# Test plot\n",
    "t_v = monitor.t/ms\n",
    "i_v = np.array(monitor.i)\n",
    "%matplotlib inline\n",
    "figure(figsize=(20,10))\n",
    "prefixes = ['Src', 'Int', 'Tgt']\n",
    "spkt = { pref : transpose([i for i in xrange(N) if pref in cell_names[i]]) \\\n",
    "        for pref in prefixes}\n",
    "clrs = ['b','r','g']\n",
    "cnt_ry = 0 \n",
    "for i in xrange(len(prefixes)):\n",
    "    pref = prefixes[i]\n",
    "    for idx in spkt[pref]:    \n",
    "        loc_ = np.where(i_v==idx)[0]     \n",
    "        t_idx = t_v[loc_]\n",
    "        plot(t_idx, np.ones(len(t_idx))*cnt_ry,'|',c=clrs[i])\n",
    "        cnt_ry += 1\n",
    "ylim([0,N])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Simulating Model Na \n",
    "#### Variations of $\\Sigma G_{elec}$ and $\\sigma_{inp}$\n",
    "50 trials of simulations each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Defining globals, constants and brian-prefs \n",
    "prefs.codegen.target = 'cython'\n",
    "\n",
    "glob = {'dt': 0.05*ms, 'tstop': 200*ms}\n",
    "const = {'E_AMPA' : 0*mV, 'E_GABA' : -80*mV, \n",
    "         'tau_AMPA' : 2*ms, 'tau_GABA' : 10*ms}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Setting up simulation parameters \n",
    "\n",
    "# Parameter vectors for variations \n",
    "num_trials = 50\n",
    "n_trial_vec = np.array(xrange(num_trials))\n",
    "t_init_std_vec = np.arange(1,11,1)\n",
    "g_elec_int_to_int_vec = np.arange(0,5.5,0.5)\n",
    "\n",
    "# This is to keep track of total number of simulations\n",
    "#     to double check if all simulations were saved if needed \n",
    "num_dat = num_trials*len(t_init_std_vec)*len(g_elec_int_to_int_vec)\n",
    "\n",
    "# This python dictionary will be saved as a struct in MATLAB\n",
    "# Simulated spike times data and indices of neurons will be saved as \n",
    "#     a struct field of 'data2save' like 'dat_000001', which is also a struct\n",
    "#     'dat_000001' is also a struct that has 3 fields \n",
    "#           'var' : 'var_tuple' -> what the varible combinations actually is \n",
    "#           'dat' : a struct of the simulated spike times \n",
    "#                 't_v' : all spike times \n",
    "#                 'idx_v' : index of the corresponding neuron \n",
    "#           'ti_inp' : the generated vector of ti_inp to Src of that trial \n",
    "# 'vars' contains variables, each of which is also a struct\n",
    "#     'order' : where this is in the 'var_tuple'\n",
    "#     'range' : the vector of variable\n",
    "#     'unit' : (not really used but helpful if needed to check during analysis in MATLAB)\n",
    "data2save = {'vars' : {'n_trial': {'order': 1, 'range': n_trial_vec, 'unit': 1}, \n",
    "                       't_init_std': {'order': 2, 'range': t_init_std_vec, 'unit': 'ms'}, \n",
    "                       'g_elec_int_to_int': {'order': 3, 'range': g_elec_int_to_int_vec, 'unit': 'nS'}},\n",
    "             'cell_names' : tuple(cell_names), \n",
    "             'cell_types' : tuple(cell_types),\n",
    "             'num_dat' : num_dat}\n",
    "\n",
    "# The following lines mean: in each set of 'save_every' = 250 sequential simulations \n",
    "#     the file will be named 'extendedNet_withGJ_moredtvariations_<cnt_save current values>.mat'\n",
    "#     like 'extendedNet_withGJ_moredtvariations_010.mat'\n",
    "# In 'extendedNet_withGJ_moredtvariations_001.mat', for example, each of the 250 simulations\n",
    "#     will be saved as a dictionary element (or struct filed in MATLAB)\n",
    "#     as 'dat_000001', 'dat_000002', ... 'dat_000250'\n",
    "# In 'extendedNet_withGJ_moredtvariations_002.mat', the struct fields/dictionary elements will be \n",
    "#     'dat_000251', 'dat_000252', ... 'dat_000500'\n",
    "file_name_prefix = 'extendedNet_withGJ_moredtvariations' \n",
    "cnt_dat = 0                    \n",
    "cnt_save = 0 \n",
    "save_every = 250\n",
    "\n",
    "# These are just to report on the progress of simulations and estimated time remaining\n",
    "# 'min_elapsed' = 1: start reporting progress after 1 minute\n",
    "# 'report_every'= 5: continue to report progress after every 5 minutes\n",
    "min_elapsed = 1\n",
    "report_every = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Running and saving simulation \n",
    "\n",
    "# Instantiate the progress bar \n",
    "fprogress = FloatProgress(min=0, max=num_dat) \n",
    "display(fprogress) # display the bar\n",
    "fprogress.description = '%.0f %s' %(0,'%')\n",
    "\n",
    "startT = time.time()\n",
    "\n",
    "# The hard-coded part and where keeping track of the order of \n",
    "#      the 'var_tuple' is very important to do analysis afterwards \n",
    "# There is a way to parallelize this rather than a bunch of nested for-loops\n",
    "#      but I didn't have much time left for the project so I ended up with this\n",
    "# A suggestion for parallelizing this is to initialize the sets of 'var_tuple' first\n",
    "#      then call it for each process. \n",
    "for g_elec_int_to_int_var in g_elec_int_to_int_vec: \n",
    "    for t_init_std_var in t_init_std_vec:           \n",
    "        for n_trial_var in n_trial_vec: \n",
    "            \n",
    "            # This is where most of the variations happen\n",
    "            var_tuple = (n_trial_var, t_init_std_var, g_elec_int_to_int_var)\n",
    "\n",
    "            syn = {('Int','ELEC','Int') : g_elec_int_to_int_var*nS/(N/3), \n",
    "                   ('Src','AMPA','Tgt') : 20*nS,\n",
    "                   ('Src','AMPA','Int') : 5*nS,\n",
    "                   ('Int','GABA','Tgt') : 10*nS, \n",
    "                   ('Int','GABA','Int') : 0*nS/(N/3)\n",
    "                    } \n",
    "            inp = {'t_init_mean': 50, 't_init_std' : t_init_std_var, 't_duration': 20}\n",
    "\n",
    "            # Calling the 'initalized' state of the network at the\n",
    "            #     'Initialization/Setting up the network stage'\n",
    "            net.restore('initialized')\n",
    "\n",
    "            # Read in and change the variations \n",
    "            for c_s in syn.keys():\n",
    "                if size(c_s) != 3 : \n",
    "                    raise ValueError('Each \"customed-synapse dict\" key needs be a 3-element tuple '\\\n",
    "                                     '(\"source_name\", \"synapse_type\", \"target_name\")')\n",
    "                for i in xrange(int(N/3)): \n",
    "                    for j in xrange(int(N/3)): \n",
    "                        if (c_s[0] == c_s[2] and i != j) or (c_s[0] != c_s[2] and i == j):\n",
    "                            src_loc = indexOfCell(cell_names,c_s[0] + '_%02d' %(i+1)) \n",
    "                            tgt_loc = indexOfCell(cell_names,c_s[2] + '_%02d' %(j+1)) \n",
    "                            val2replace = syn[c_s] \n",
    "                            if c_s[1].upper() == 'ELEC': # SYMMETRICAL ELECTRICAL SYNAPSE \n",
    "                                S_elec.g_elec[S_elec.indices[src_loc,tgt_loc]] = val2replace \n",
    "                                S_elec.g_elec[S_elec.indices[tgt_loc,src_loc]] = val2replace\n",
    "                            elif c_s[1].upper() == 'AMPA':\n",
    "                                S_AMPA.g_AMPA[S_AMPA.indices[src_loc,tgt_loc]] = val2replace\n",
    "                            elif c_s[1].upper() == 'GABA':\n",
    "                                S_GABA.g_GABA[S_GABA.indices[src_loc,tgt_loc]] = val2replace\n",
    "                            else: \n",
    "                                raise ValueError('Cannot accept any other values like \"%s\" representing '\\\n",
    "                                                 'synapses except \"0\", \"ELEC\", \"AMPA\" or \"GABA\"' %(c_s[1]))  \n",
    "            # Input to Src\n",
    "            init_states['i0'] = np.zeros(N) * pA\n",
    "            init_states['ti'] = np.zeros(N) * ms\n",
    "            init_states['tf'] = np.zeros(N) * ms\n",
    "            init_states['i_hold'] = np.zeros(N) * pA\n",
    "\n",
    "            ti_inp = np.sort(np.random.normal(inp['t_init_mean'],inp['t_init_std'],int(N/3)+1))\n",
    "            while size(np.where(np.logical_and(ti_inp < 0, ti_inp > glob['tstop']/ms - 100))[0]) > 0:\n",
    "                ti_inp = np.sort(np.random.normal(inp['t_init_mean'],inp['t_init_std'],int(N/3)+1))\n",
    "            td_inp = inp['t_duration']\n",
    "            saved_td_inp = [] \n",
    "            \n",
    "            # Applying inputs to Src and neccessary holding currents, as well as change Tgt to make more excitable\n",
    "            for i in xrange(N): \n",
    "                c_n = cell_names[i]\n",
    "                if 'Int' in c_n : \n",
    "                    init_states['i_hold'][i] = 50*pA\n",
    "                if 'Src' in c_n :\n",
    "                    if size(ti_inp) != 0:\n",
    "                        ti_i = ti_inp[-1]; ti_inp = ti_inp[:-1]\n",
    "                        saved_td_inp.append(ti_i)\n",
    "                        init_states['i0'][i] = 300*pA\n",
    "                        init_states['ti'][i] = ti_i*ms\n",
    "                        init_states['tf'][i] = (ti_i+td_inp)*ms\n",
    "                if 'Tgt' in c_n : \n",
    "                    init_states['i_hold'][i] = 10*pA\n",
    "                    init_states['v_t'][i] = -45*mV\n",
    "                    init_vals['C'][i] = 50*pF\n",
    "            G.set_states(init_states)\n",
    "            defaultclock.dt = glob['dt']\n",
    "            \n",
    "            # Run the simulation \n",
    "            net.run(glob['tstop'])\n",
    "\n",
    "            # Getting the data \n",
    "            t_v = monitor.t/ms\n",
    "            idx_v = np.array(monitor.i)\n",
    "\n",
    "            tmp_dict = {'var' : var_tuple, \n",
    "                        'dat' : {'t_v': t_v, 'idx_v' : idx_v}, \n",
    "                        'ti_inp' : saved_td_inp\n",
    "                       }\n",
    "\n",
    "            cnt_dat += 1 \n",
    "            name_field = 'dat_%06d' %(cnt_dat)\n",
    "            data2save[name_field] = tmp_dict\n",
    "            \n",
    "            # Reporting and saving the data chunks \n",
    "            fprogress.value += 1\n",
    "            percent_complete = 100*(cnt_dat/num_dat)\n",
    "            fprogress.description = '%.0f %s' %(percent_complete,'%')\n",
    "\n",
    "            currT = time.time() \n",
    "            curr_elapsed = (currT - startT)/60\n",
    "            if curr_elapsed >= min_elapsed and (np.round(curr_elapsed) % min_elapsed) == 0: \n",
    "                estTleft = 100*curr_elapsed/percent_complete - curr_elapsed\n",
    "                print('%.2f min - %.0f %s progress, est. %.2f min left' %(curr_elapsed,percent_complete,'%',estTleft))\n",
    "                min_elapsed += report_every\n",
    "\n",
    "            if (cnt_dat > 0 and (cnt_dat % save_every) == 0) or cnt_dat == num_dat: \n",
    "                cnt_save += 1\n",
    "                name_saved_file = '%s_%03d.mat' %(file_name_prefix, cnt_save)\n",
    "                scio.savemat(name_saved_file, {'data2save' : data2save})\n",
    "                print('\\t + %s was saved' %(name_saved_file))\n",
    "                del data2save\n",
    "                \n",
    "                # This needs to be exactly as the one in 'Setting up simulation parameters'\n",
    "                # A better way to do this is just to create a function to easily call it \n",
    "                #        without the manual copy and paste \n",
    "                data2save = {'vars' : {'n_trial': {'order': 1, 'range': n_trial_vec, 'unit': 1}, \n",
    "                                       't_init_std': {'order': 2, 'range': t_init_std_vec, 'unit': 'ms'}, \n",
    "                                       'g_elec_int_to_int': {'order': 3, 'range': g_elec_int_to_int_vec, 'unit': 'nS'}},\n",
    "                             'cell_names' : tuple(cell_names), \n",
    "                             'cell_types' : tuple(cell_types),\n",
    "                             'num_dat' : num_dat}\n",
    "\n",
    "endT = time.time()\n",
    "print('Total time elapsed = %.3f m' %((endT-startT)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Simulating Model Nb\n",
    "#### Variations of $\\Sigma G_{elec}$ and $\\sigma_{inp}$ with a presence of a fixed $\\Sigma G_{GABA \\rightarrow Int}$\n",
    "50 trials of simulations each\n",
    "\n",
    "Run each simulation by changing 'g_GABA_Int2Int_total' and 'file_name_prefix' accordingly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Setting up simulation \n",
    "g_GABA_Int2Int_total = 1 # change to 3 or 5 for each run \n",
    "num_trials = 50\n",
    "n_trial_vec = np.array(xrange(num_trials))\n",
    "t_init_std_vec = np.arange(1,11,1)\n",
    "g_elec_int_to_int_vec = np.arange(0,5.5,0.5)\n",
    "num_dat = num_trials*len(t_init_std_vec)*len(g_elec_int_to_int_vec)\n",
    "data2save = {'vars' : {'n_trial': {'order': 1, 'range': n_trial_vec, 'unit': 1}, \n",
    "                       't_init_std': {'order': 2, 'range': t_init_std_vec, 'unit': 'ms'}, \n",
    "                       'g_elec_int_to_int': {'order': 3, 'range': g_elec_int_to_int_vec, 'unit': 'nS'}},\n",
    "             'cell_names' : tuple(cell_names), \n",
    "             'cell_types' : tuple(cell_types),\n",
    "             'num_dat' : num_dat}\n",
    "file_name_prefix = 'extendedNet_withGJandGABA=%01dnS' %(g_GABA_Int2Int_total)\n",
    "cnt_dat = 0 \n",
    "cnt_save = 0 \n",
    "save_every = 250\n",
    "min_elapsed = 1\n",
    "report_every = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Running and saving simulation \n",
    "fprogress = FloatProgress(min=0, max=num_dat) # instantiate the bar\n",
    "display(fprogress) # display the bar\n",
    "fprogress.description = '%.0f %s' %(0,'%')\n",
    "\n",
    "startT = time.time()\n",
    "for g_elec_int_to_int_var in g_elec_int_to_int_vec: \n",
    "    for t_init_std_var in t_init_std_vec:           \n",
    "        for n_trial_var in n_trial_vec: \n",
    "            var_tuple = (n_trial_var, t_init_std_var, g_elec_int_to_int_var)\n",
    "\n",
    "            syn = {('Int','ELEC','Int') : g_elec_int_to_int_var*nS/(N/3), \n",
    "                   ('Src','AMPA','Tgt') : 20*nS,\n",
    "                   ('Src','AMPA','Int') : 5*nS,\n",
    "                   ('Int','GABA','Tgt') : 10*nS, \n",
    "                   ('Int','GABA','Int') : g_GABA_Int2Int_total*nS/(N/3)\n",
    "                    } \n",
    "            inp = {'t_init_mean': 50, 't_init_std' : t_init_std_var, 't_duration': 20}\n",
    "\n",
    "            net.restore('initialized')\n",
    "\n",
    "            for c_s in syn.keys():\n",
    "                if size(c_s) != 3 : \n",
    "                    raise ValueError('Each \"customed-synapse dict\" key needs be a 3-element tuple '\\\n",
    "                                     '(\"source_name\", \"synapse_type\", \"target_name\")')\n",
    "                for i in xrange(int(N/3)): \n",
    "                    for j in xrange(int(N/3)): \n",
    "                        if (c_s[0] == c_s[2] and i != j) or (c_s[0] != c_s[2] and i == j):\n",
    "                            src_loc = indexOfCell(cell_names,c_s[0] + '_%02d' %(i+1)) \n",
    "                            tgt_loc = indexOfCell(cell_names,c_s[2] + '_%02d' %(j+1)) \n",
    "                            val2replace = syn[c_s] \n",
    "                            if c_s[1].upper() == 'ELEC': # SYMMETRICAL ELECTRICAL SYNAPSE \n",
    "                                S_elec.g_elec[S_elec.indices[src_loc,tgt_loc]] = val2replace \n",
    "                                S_elec.g_elec[S_elec.indices[tgt_loc,src_loc]] = val2replace # redundant \n",
    "                            elif c_s[1].upper() == 'AMPA':\n",
    "                                S_AMPA.g_AMPA[S_AMPA.indices[src_loc,tgt_loc]] = val2replace\n",
    "                            elif c_s[1].upper() == 'GABA':\n",
    "                                S_GABA.g_GABA[S_GABA.indices[src_loc,tgt_loc]] = val2replace\n",
    "                            else: \n",
    "                                raise ValueError('Cannot accept any other values like \"%s\" representing '\\\n",
    "                                                 'synapses except \"0\", \"ELEC\", \"AMPA\" or \"GABA\"' %(c_s[1]))  \n",
    "\n",
    "            init_states['i0'] = np.zeros(N) * pA\n",
    "            init_states['ti'] = np.zeros(N) * ms\n",
    "            init_states['tf'] = np.zeros(N) * ms\n",
    "            init_states['i_hold'] = np.zeros(N) * pA\n",
    "\n",
    "            ti_inp = np.sort(np.random.normal(inp['t_init_mean'],inp['t_init_std'],int(N/3)+1))\n",
    "            while size(np.where(np.logical_and(ti_inp < 0, ti_inp > glob['tstop']/ms - 100))[0]) > 0:\n",
    "                ti_inp = np.sort(np.random.normal(inp['t_init_mean'],inp['t_init_std'],int(N/3)+1))\n",
    "            td_inp = inp['t_duration']\n",
    "            saved_td_inp = [] \n",
    "\n",
    "            for i in xrange(N): \n",
    "                c_n = cell_names[i]\n",
    "                if 'Int' in c_n : \n",
    "                    init_states['i_hold'][i] = 50*pA\n",
    "                if 'Src' in c_n :\n",
    "                    if size(ti_inp) != 0:\n",
    "                        ti_i = ti_inp[-1]; ti_inp = ti_inp[:-1]\n",
    "                        saved_td_inp.append(ti_i)\n",
    "                        init_states['i0'][i] = 300*pA\n",
    "                        init_states['ti'][i] = ti_i*ms\n",
    "                        init_states['tf'][i] = (ti_i+td_inp)*ms\n",
    "                if 'Tgt' in c_n : \n",
    "                    init_states['i_hold'][i] = 10*pA\n",
    "                    init_states['v_t'][i] = -45*mV\n",
    "                    init_vals['C'][i] = 50*pF\n",
    "            G.set_states(init_states)\n",
    "            defaultclock.dt = glob['dt']\n",
    "            net.run(glob['tstop'])\n",
    "\n",
    "            t_v = monitor.t/ms\n",
    "            idx_v = np.array(monitor.i)\n",
    "\n",
    "            tmp_dict = {'var' : var_tuple, \n",
    "                        'dat' : {'t_v': t_v, 'idx_v' : idx_v}, \n",
    "                        'ti_inp' : saved_td_inp\n",
    "                       }\n",
    "\n",
    "            cnt_dat += 1 \n",
    "            name_field = 'dat_%06d' %(cnt_dat)\n",
    "            data2save[name_field] = tmp_dict\n",
    "            fprogress.value += 1\n",
    "            percent_complete = 100*(cnt_dat/num_dat)\n",
    "            fprogress.description = '%.0f %s' %(percent_complete,'%')\n",
    "\n",
    "            currT = time.time() \n",
    "            curr_elapsed = (currT - startT)/60\n",
    "            if curr_elapsed >= min_elapsed and (np.round(curr_elapsed) % min_elapsed) == 0: \n",
    "                estTleft = 100*curr_elapsed/percent_complete - curr_elapsed\n",
    "                print('%.2f min - %.0f %s progress, est. %.2f min left' %(curr_elapsed,percent_complete,'%',estTleft))\n",
    "                min_elapsed += report_every\n",
    "\n",
    "            if (cnt_dat > 0 and (cnt_dat % save_every) == 0) or cnt_dat == num_dat: \n",
    "                cnt_save += 1\n",
    "                name_saved_file = '%s_%03d.mat' %(file_name_prefix, cnt_save)\n",
    "                scio.savemat(name_saved_file, {'data2save' : data2save})\n",
    "                print('\\t + %s was saved' %(name_saved_file))\n",
    "                del data2save\n",
    "\n",
    "                data2save = {'vars' : {'n_trial': {'order': 1, 'range': n_trial_vec, 'unit': 1}, \n",
    "                                       't_init_std': {'order': 2, 'range': t_init_std_vec, 'unit': 'ms'}, \n",
    "                                       'g_elec_int_to_int': {'order': 3, 'range': g_elec_int_to_int_vec, 'unit': 'nS'}},\n",
    "                             'cell_names' : tuple(cell_names), \n",
    "                             'cell_types' : tuple(cell_types),\n",
    "                             'num_dat' : num_dat}\n",
    "\n",
    "endT = time.time()\n",
    "print('Total time elapsed = %.3f m' %((endT-startT)/60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
